{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7a6343",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61232e",
   "metadata": {},
   "source": [
    "1. Set a goal for the prompt.\n",
    "\n",
    "    **Ex:** *Write a prompt that generates a 1-day meal plan for an athelete based upon their hight, weight, goal and dietary restrictions.*\n",
    "2. Write an initial prompt.\n",
    "3. Eval the prompt.\n",
    "4. Apply a prompt engineering technique.\n",
    "5. Re-eval to verify better performance .\n",
    "6. repeat 4 & 5 until satisfied with performance.\n",
    "\n",
    "\n",
    "*Note – New classes were created for this notebook:*\n",
    "- ClaudeResponsesClass: functions to chat with Claude.\n",
    "- PromptEvaluatorClass: functions to evaluate responses by a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e815c0",
   "metadata": {},
   "source": [
    "#### Import classes and set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e03309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.PromptEvaluatorClass import PromptEvaluator\n",
    "from lib.ClaudeResponsesClass import ClaudeResponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e7c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of PromptEvaluator\n",
    "evaluator = PromptEvaluator(max_concurrent_tasks=3)\n",
    "# Create an instance of ClaudeResponses\n",
    "claude = ClaudeResponses(save_history=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab35788",
   "metadata": {},
   "source": [
    "#### Generate sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba923b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1/3 test cases\n",
      "Generated 2/3 test cases\n",
      "Generated 3/3 test cases\n"
     ]
    }
   ],
   "source": [
    "dataset_file = \"03_PromptEngineering_outputs/sample_dataset.json\"\n",
    "dataset = evaluator.generate_dataset(\n",
    "    # Describe the purpose of the prompt you're trying to test\n",
    "    task_description=\"Write a compact, concise 1 day meal plan for a single athlete\",\n",
    "    # Decribe the different imputs that your prompt requires\n",
    "    prompt_inputs_spec={\n",
    "        \"height\": \"Athlete's height in cm\",\n",
    "        \"weight\": \"Athlete's weight in kg\", \n",
    "        \"goal\": \"Goal of the athlete\",\n",
    "        \"restrictions\": \"Dietary restrictions of the athlete\"\n",
    "    },\n",
    "    # Where to write the generated dataset\n",
    "    output_file=dataset_file,\n",
    "    # Number of test cases to generate\n",
    "    num_cases=3,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b099db",
   "metadata": {},
   "source": [
    "#### Simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d375ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function containing prompt\n",
    "def run_prompt(prompt_inputs):\n",
    "    prompt = f\"\"\"\n",
    "    What should this person eat?\n",
    "\n",
    "    - Height: {prompt_inputs[\"height\"]}\n",
    "    - Weight: {prompt_inputs[\"weight\"]}\n",
    "    - Goal: {prompt_inputs[\"goal\"]}\n",
    "    - Dietary restrictions: {prompt_inputs[\"restrictions\"]}\n",
    "    \"\"\"\n",
    "    return claude.chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c447a3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graded 1/3 test cases\n",
      "Graded 2/3 test cases\n",
      "Graded 3/3 test cases\n",
      "Average score: 3\n"
     ]
    }
   ],
   "source": [
    "extra_criteria = \"\"\"\n",
    "The output should include:\n",
    "- Daily caloric total\n",
    "- Macronutrient breakdown  \n",
    "- Meals with exact foods, portions, and timing\n",
    "\"\"\"\n",
    "results = evaluator.run_evaluation(\n",
    "    run_prompt_function=run_prompt,\n",
    "    dataset_file=\"03_PromptEngineering_outputs/sample_dataset.json\",\n",
    "    extra_criteria=extra_criteria,\n",
    "json_output_file=\"03_PromptEngineering_outputs/sample_json_output.json\",\n",
    "html_output_file=\"03_PromptEngineering_outputs/sample_html_output.html\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e6382",
   "metadata": {},
   "source": [
    "## 1. Be clear and direct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a1d2e",
   "metadata": {},
   "source": [
    "First line of prompt: tends to be the most important. Set the action and provide the task; set basic expectations for the output.\n",
    "\n",
    "**Clear**\n",
    "- Use simple language\n",
    "- State what you want explicitly.\n",
    "- Lead your prompt with a simple statement of the model's task.\n",
    "\n",
    "**Direct**\n",
    "- Use instructions, not questions.\n",
    "- Use direct action verbs (write, create, generate, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c4e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt_inputs):\n",
    "    # Direct action verb at the start\n",
    "    # Direct task in simple language\n",
    "    prompt = f\"\"\"\n",
    "    Generate a one-day meal plan for an athlete that meets their dietary restrictions.\n",
    "\n",
    "    - Height: {prompt_inputs[\"height\"]}\n",
    "    - Weight: {prompt_inputs[\"weight\"]}\n",
    "    - Goal: {prompt_inputs[\"goal\"]}\n",
    "    - Dietary restrictions: {prompt_inputs[\"restrictions\"]}\n",
    "    \"\"\"\n",
    "    return claude.chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f47a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt(run_prompt_function, file):\n",
    "    results = evaluator.run_evaluation(\n",
    "    run_prompt_function=run_prompt_function,\n",
    "    dataset_file=dataset_file,\n",
    "    extra_criteria=extra_criteria,\n",
    "    json_output_file=f\"03_PromptEngineering_outputs/{file}.json\",\n",
    "    html_output_file=f\"03_PromptEngineering_outputs/{file}.html\"\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb2300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graded 1/3 test cases\n",
      "Graded 2/3 test cases\n",
      "Graded 3/3 test cases\n",
      "Average score: 6\n"
     ]
    }
   ],
   "source": [
    "file = \"clear_direct_prompt\"\n",
    "\n",
    "results = eval_prompt(run_prompt, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32efae",
   "metadata": {},
   "source": [
    "## 2. Be Specific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ef065",
   "metadata": {},
   "source": [
    "Provide clead guidelines/steps that direct Claude to the desired output.\n",
    "- List qualities that output should have: length of the response, structure and format, specific attributes or elements to inclure, tone or style requirements. \n",
    "    - Use in practically every prompt.\n",
    "- Provide steps the model should follow: steps that will help it think through a problem systematically or consider multiple perspectives.\n",
    "    - Use to troubleshoot problems, decision-making, critical thinking, or any situation to consider multiple angles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc25d39",
   "metadata": {},
   "source": [
    "#### Guidelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt_inputs):\n",
    "    # Direct action verb at the start\n",
    "    # Direct task in simple language\n",
    "    prompt = f\"\"\"\n",
    "    Generate a one-day meal plan for an athlete that meets their dietary restrictions.\n",
    "\n",
    "    - Height: {prompt_inputs[\"height\"]}\n",
    "    - Weight: {prompt_inputs[\"weight\"]}\n",
    "    - Goal: {prompt_inputs[\"goal\"]}\n",
    "    - Dietary restrictions: {prompt_inputs[\"restrictions\"]}\n",
    "\n",
    "    Guidelines:\n",
    "    1. Include accurate daily calorie amount\n",
    "    2. Show protein, fat, and carb amounts  \n",
    "    3. Specify when to eat each meal\n",
    "    4. Use only foods that fit restrictions\n",
    "    5. List all portion sizes in grams\n",
    "    6. Keep budget-friendly if mentioned\n",
    "    \"\"\"\n",
    "    return claude.chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dc6882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graded 1/3 test cases\n",
      "Graded 2/3 test cases\n",
      "Graded 3/3 test cases\n",
      "Average score: 6.333333333333333\n"
     ]
    }
   ],
   "source": [
    "file = \"guidelines_prompt\"\n",
    "\n",
    "results = eval_prompt(run_prompt, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87d340",
   "metadata": {},
   "source": [
    "#### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f5d4d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt_inputs):\n",
    "    # Direct action verb at the start\n",
    "    # Direct task in simple language\n",
    "    prompt = f\"\"\"\n",
    "    Generate a one-day meal plan for an athlete that meets their dietary restrictions.\n",
    "\n",
    "    - Height: {prompt_inputs[\"height\"]}\n",
    "    - Weight: {prompt_inputs[\"weight\"]}\n",
    "    - Goal: {prompt_inputs[\"goal\"]}\n",
    "    - Dietary restrictions: {prompt_inputs[\"restrictions\"]}\n",
    "\n",
    "    Follow these steps:\n",
    "    1. Calculate daily calories needed\n",
    "    2. Figure out protein, fat, carb amounts\n",
    "    3. Plan meal timing around workouts\n",
    "    4. Choose foods that fit restrictions\n",
    "    5. set portion sizes in grams\n",
    "    6. Adjust for budget if needed\n",
    "    \"\"\"\n",
    "    return claude.chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "654eb96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graded 1/3 test cases\n",
      "Graded 2/3 test cases\n",
      "Graded 3/3 test cases\n",
      "Average score: 8.666666666666666\n"
     ]
    }
   ],
   "source": [
    "file = \"steps_prompt\"\n",
    "\n",
    "results = eval_prompt(run_prompt, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d91e48",
   "metadata": {},
   "source": [
    "## 3. Structure with XML tags and Provide examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5781fc76",
   "metadata": {},
   "source": [
    "Use **XML** tags to separate distinct portions of the prompt.\n",
    "- Most useful when including a lot of context.\n",
    "- Help serve as delimiters for the model.\n",
    "\n",
    "Give the model sample input/output pairs.\n",
    "- Useful for capturing corner cases or complex output formats\n",
    "- *\"One-Shot*: provide a single example\n",
    "- *\"Multi-Shot*: provide multiple examples\n",
    "- Combine with XML Tags for structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt_inputs):\n",
    "    prompt = f\"\"\"\n",
    "    Generate a one-day meal plan for an athlete that meets their dietary restrictions.\n",
    "\n",
    "    <athlete_information>\n",
    "    - Height: {prompt_inputs[\"height\"]}\n",
    "    - Weight: {prompt_inputs[\"weight\"]}\n",
    "    - Goal: {prompt_inputs[\"goal\"]}\n",
    "    - Dietary restrictions: {prompt_inputs[\"restrictions\"]}\n",
    "    </athlete_information>\n",
    "    \n",
    "    Follow these steps:\n",
    "    1. Calculate daily calories needed\n",
    "    2. Figure out protein, fat, carb amounts\n",
    "    3. Plan meal timing around workouts\n",
    "    4. Choose foods that fit restrictions\n",
    "    5. set portion sizes in grams\n",
    "    6. Adjust for budget if needed\n",
    "\n",
    "    Here's an example with a sample input and an ideal output:\n",
    "    SAMPLE INPUT:\n",
    "    <sample_input>\n",
    "    - Height: 180\n",
    "    - Weight: 85\n",
    "    - Goal: muscle maintenance and performance optimization during training season\n",
    "    - Restrictions: lactose intolerant, limited budget for groceries\n",
    "    </sample_input>\n",
    "\n",
    "    IDEAL OUTPUT:\n",
    "    <ideal_output>\n",
    "    1. Daily Calorie Calculation:\n",
    "    - Assuming moderate to high activity level\n",
    "    - Basal Metabolic Rate (BMR) using Mifflin-St Jeor Equation:\n",
    "        BMR = (10 × weight) + (6.25 × height) - (5 × age) + 5\n",
    "        Assuming age 25: BMR ≈ 1,925 calories\n",
    "    - Activity multiplier (training season): 1.7\n",
    "    - Total Daily Energy Expenditure (TDEE): 1,925 × 1.7 = 3,270 calories\n",
    "\n",
    "    2. Macronutrient Breakdown:\n",
    "    - Protein: 2.2g per kg of body weight\n",
    "        85 kg × 2.2 = 187g protein (748 calories)\n",
    "    - Carbohydrates: 5-7g per kg of body weight\n",
    "        85 kg × 6 = 510g carbs (2,040 calories)\n",
    "    - Fats: Remaining calories\n",
    "        3,270 - (748 + 2,040) = 482 calories (54g fat)\n",
    "\n",
    "    3. Meal Timing:\n",
    "    - Pre-workout meal: Complex carbs, lean protein\n",
    "    - Post-workout meal: High protein, quick-absorbing carbs\n",
    "    - Meals spread 3-4 hours apart\n",
    "\n",
    "    4. Lactose-Free, Budget-Friendly Meal Plan:\n",
    "\n",
    "    Breakfast (7:00 AM) - 700 calories:\n",
    "    - Oatmeal (100g dry)\n",
    "    - Plant-based protein powder (30g)\n",
    "    - Banana (100g)\n",
    "    - Almond butter (15g)\n",
    "    - Chia seeds (10g)\n",
    "\n",
    "    Mid-Morning Snack (10:00 AM) - 350 calories:\n",
    "    - Rice cakes (50g)\n",
    "    - Canned tuna (100g)\n",
    "    - Avocado (50g)\n",
    "\n",
    "    Lunch (1:00 PM) - 800 calories:\n",
    "    - Chicken breast (150g)\n",
    "    - Brown rice (100g)\n",
    "    - Mixed vegetables (200g)\n",
    "    - Olive oil (15ml)\n",
    "\n",
    "    Pre-Workout Snack (4:00 PM) - 400 calories:\n",
    "    - Sweet potato (150g)\n",
    "    - Turkey breast (100g)\n",
    "    - Spinach (50g)\n",
    "\n",
    "    Post-Workout Meal (6:00 PM) - 700 calories:\n",
    "    - Lean ground beef (120g)\n",
    "    - Quinoa (100g)\n",
    "    - Black beans (100g)\n",
    "    - Mixed vegetables (150g)\n",
    "\n",
    "    Evening Snack (9:00 PM) - 320 calories:\n",
    "    - Egg whites (100g)\n",
    "    - Oats (50g)\n",
    "    - Berries (100g)\n",
    "\n",
    "    5. Nutritional Breakdown:\n",
    "    - Total Calories: 3,270\n",
    "    - Protein: 187g\n",
    "    - Carbohydrates: 510g\n",
    "    - Fat: 54g\n",
    "\n",
    "    6. Budget Considerations:\n",
    "    - Bulk buying proteins (chicken, ground beef)\n",
    "    - Frozen vegetables\n",
    "    - Canned proteins\n",
    "    - Buying in-season produce\n",
    "    - Buying larger packages of staples like rice, oats\n",
    "\n",
    "    Additional Notes:\n",
    "    - Drink 3-4 liters of water daily\n",
    "    - Use seasonings and herbs for flavor\n",
    "    - Adjust portions if needed based on individual response\n",
    "\n",
    "    Supplements to Consider (Optional):\n",
    "    - Lactose-free protein powder\n",
    "    - Multivitamin\n",
    "    - Creatine monohydrate\n",
    "\n",
    "    Recommendations:\n",
    "    - Meal prep to save time and money\n",
    "    - Rotate protein sources for variety\n",
    "    - Monitor body's response and adjust as needed\n",
    "    </ideal_output>\n",
    "\n",
    "    The sample output thoroughly meets all mandatory requirements by providing a precise daily meal plan with exact caloric intake (3,270 calories), detailed macronutrient breakdown, specific meals with portions and timing, and accommodations for lactose intolerance. The plan demonstrates careful nutritional engineering for an athlete's performance needs while respecting budget constraints.\n",
    "    \"\"\"\n",
    "    return claude.chat(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20c5df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graded 1/3 test cases\n",
      "Graded 2/3 test cases\n",
      "Graded 3/3 test cases\n",
      "Average score: 8.333333333333334\n"
     ]
    }
   ],
   "source": [
    "file = \"xml_tags_examples\"\n",
    "\n",
    "results = eval_prompt(run_prompt, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb5f36",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036e5d7a",
   "metadata": {},
   "source": [
    "Goal: improve an existing prompt to take in a passage of text and extract topics into a JSON array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f639b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1/5 test cases\n",
      "Generated 2/5 test cases\n",
      "Generated 3/5 test cases\n",
      "Generated 4/5 test cases\n",
      "Generated 5/5 test cases\n"
     ]
    }
   ],
   "source": [
    "dataset_file = \"03_PromptEngineering_outputs/exercise_dataset.json\"\n",
    "dataset = evaluator.generate_dataset(\n",
    "    task_description=\"Extract topics out of a passage of text from a scholarly article into a JSON array of strings\",\n",
    "    prompt_inputs_spec={\"content\": \"One paragraph of text from a scholarly journal written in English\"},\n",
    "    output_file=dataset_file,\n",
    "    num_cases=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32692e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(prompt_inputs):\n",
    "    prompt = f\"\"\"\n",
    "    Extract key topics mentioned from a passage of text from a scholarly journal into a JSON array of strings.\n",
    "\n",
    "    <text>\n",
    "    {prompt_inputs[\"content\"]}\n",
    "    </text> \n",
    "\n",
    "    Follow these steps:\n",
    "    1. Closely examine the provided text\n",
    "    2. Identify each topic mentioned\n",
    "    3. Add each topic to a JSON array\n",
    "    4. Respond with the JSON array. Do not provide any other text or commentary.\n",
    "    \"\"\"\n",
    "    return claude.chat(prompt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5dee773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graded 1/5 test cases\n",
      "Graded 2/5 test cases\n",
      "Graded 3/5 test cases\n",
      "Graded 4/5 test cases\n",
      "Graded 5/5 test cases\n",
      "Average score: 9\n"
     ]
    }
   ],
   "source": [
    "file = \"exercise\"\n",
    "extra_criteria = \"\"\"\n",
    "- Contains a JSON array of strings, containing each topic mentioned in the article.\n",
    "- The strings should contain only a topic without any extra commentary.\n",
    "- Response should contain the JSON array and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "results = eval_prompt(run_prompt, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
