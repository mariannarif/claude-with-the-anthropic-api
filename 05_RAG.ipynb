{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20b7072",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4520e4",
   "metadata": {},
   "source": [
    "To include context for Claude, long prompts cost more money and time to process, and Claude is slightly less effective. \n",
    "\n",
    "##### With RAG:\n",
    "1. Break up the document in chunks\n",
    "2. Feed only relevant chunks to the prompt\n",
    "\n",
    "<br>\n",
    "\n",
    "| Upsides | Downsides |\n",
    "| -- | -- |\n",
    "| - Focus on relevant content only <br> - Scale to large & multiple docs. <br> - Smaller prompt (cheaper and faster) | - Pre-procesing <br> - Needs searching mechanism to find relevant chunk <br> - May leave out some relevant content <br> - Many ways to chunk the text | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ebc14",
   "metadata": {},
   "source": [
    "#### Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0faa91cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mi40985/Documents/Cursos/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import voyageai\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# add VOYAGE_API_KEY to .env\n",
    "embedding_client = voyageai.Client()\n",
    "\n",
    "# Claude\n",
    "client = Anthropic()\n",
    "model = \"claude-3-7-sonnet-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9de8e053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from math import sqrt\n",
    "from lib.SearchStrategiesClass import VectorIndex, BM25Index, Retriever\n",
    "from lib.ClaudeResponsesClass import ClaudeResponses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a42bda",
   "metadata": {},
   "source": [
    "## 1. Chunking Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba421dd",
   "metadata": {},
   "source": [
    "| Size Based | Structure Based | Semantic Based |\n",
    "| -- | -- | -- |\n",
    "| Divide text into strings of equal length (overlap sections to include some context) | Divide text based upon structure (headers, paragraphs, sections, ...) | Divide into groups of related sentences or sections |\n",
    "| Easy to implement | Keeps related content in the same chunk | Needs to understand meaning of individual sentences |\n",
    "| Can be repetitive, migh separate related content | Needs us to understand the structure of the document beforehand | Computationally expensive, but more relevant chunks |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dfd613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"report.md\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8374203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk by a set number of characters\n",
    "def chunk_by_char(text: str,\n",
    "                  chunk_size: int = 150,\n",
    "                  chunk_overlap: int = 20\n",
    "):\n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "    while start_idx < len(text):\n",
    "        end_idx = min(start_idx + chunk_size, len(text))\n",
    "        chunk = text[start_idx:end_idx]\n",
    "        chunks.append(chunk)\n",
    "        start_idx = (\n",
    "            end_idx - chunk_overlap if end_idx < len(text) else len(text)\n",
    "        )\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0771df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# **Annual Interdisciplinary Research Review: Cross-Domain Insights**\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "This report synthesizes the key findings and ongoing rese\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      "ngs and ongoing research efforts across the organization's diverse operational and R&D departments for the past fiscal year. Our strength lies in the \n",
      "\n",
      " -------------------------------- \n",
      " \n",
      "trength lies in the cross-pollination of ideas and methodologies, driving innovation and addressing complex challenges that transcend traditional disc\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      "end traditional disciplinary boundaries. This year's review highlights significant progress in ten critical areas. Advances in **Medical Research** fo\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      "edical Research** focused on the rare XDR-471 syndrome, yielding new diagnostic insights. Concurrently, **Software Engineering** tackled persistent st\n",
      "\n",
      " -------------------------------- \n",
      " \n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_by_char(text)\n",
    "\n",
    "for chunk in chunks[0:5]:\n",
    "    print(chunk + \"\\n\\n -------------------------------- \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82879ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk by sentence\n",
    "def chunk_by_sentence(text: str,\n",
    "                      max_sentences: int = 5,\n",
    "                      overlap_sentences: int = 1\n",
    "):\n",
    "    sentences = re.split(r\"(?<=[.!?])\\s+\", text)\n",
    "    chunks = []\n",
    "    start_idx = 0\n",
    "    while start_idx < len(sentences):\n",
    "        end_idx = min(start_idx + max_sentences, len(sentences))\n",
    "        chunk = sentences[start_idx:end_idx]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "\n",
    "        start_idx += max_sentences - overlap_sentences\n",
    "\n",
    "        if start_idx < 0:\n",
    "            start_idx = 0\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb6a9cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# **Annual Interdisciplinary Research Review: Cross-Domain Insights**\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "This report synthesizes the key findings and ongoing research efforts across the organization's diverse operational and R&D departments for the past fiscal year. Our strength lies in the cross-pollination of ideas and methodologies, driving innovation and addressing complex challenges that transcend traditional disciplinary boundaries. This year's review highlights significant progress in ten critical areas. Advances in **Medical Research** focused on the rare XDR-471 syndrome, yielding new diagnostic insights. Concurrently, **Software Engineering** tackled persistent stability issues, implementing key fixes identified through error code analysis (e.g., `ERR_MEM_ALLOC_FAIL_0x8007000E`).\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      "Concurrently, **Software Engineering** tackled persistent stability issues, implementing key fixes identified through error code analysis (e.g., `ERR_MEM_ALLOC_FAIL_0x8007000E`). **Financial Analysis** revealed mixed quarterly performance, prompting strategic reviews, particularly concerning resource allocation impacting R&D pipelines. Crucial developments were also seen in **Scientific Experimentation**, where novel material properties were characterized, potentially impacting future product lines. Our **Legal Developments** team navigated complex precedents, particularly in intellectual property related to the _Synergy Dynamics_ case, ensuring compliance and mitigating risk. **Product Engineering** finalized specifications for the next-generation Model Zircon-5, incorporating feedback from multiple teams.\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      "**Product Engineering** finalized specifications for the next-generation Model Zircon-5, incorporating feedback from multiple teams. Insights from **Historical Research** into the Galveston Accords provided unexpected context for current market dynamics. **Project Management** successfully navigated critical phases for Project Cerberus despite resource constraints, documented through detailed progress reports. **Pharmaceutical Development** advanced Compound CTX-204b into further testing based on promising biomarker results. Finally, **Cybersecurity Analysis** addressed sophisticated threats, reinforcing our defenses based on detailed incident forensics.\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      "Finally, **Cybersecurity Analysis** addressed sophisticated threats, reinforcing our defenses based on detailed incident forensics. These collective efforts underscore the value of our integrated approach. ## Table of Contents\n",
      "\n",
      "1. Executive Summary\n",
      "2. Table of Contents\n",
      "3.\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      "Table of Contents\n",
      "3. Methodology\n",
      "4. Section 1: Medical Research - Understanding XDR-471 Syndrome\n",
      "5. Section 2: Software Engineering - Project Phoenix Stability Enhancements\n",
      "6. Section 3: Financial Analysis - Q3 Performance and Outlook\n",
      "7.\n",
      "\n",
      " -------------------------------- \n",
      " \n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_by_sentence(text)\n",
    "\n",
    "for chunk in chunks[0:5]:\n",
    "    print(chunk + \"\\n\\n -------------------------------- \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb069cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk by section (example for markdown)\n",
    "def chunk_by_section(document_text, pattern = r\"\\n##\"):\n",
    "    return re.split(pattern, document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b654db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# **Annual Interdisciplinary Research Review: Cross-Domain Insights**\n",
      "\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      " Executive Summary\n",
      "\n",
      "This report synthesizes the key findings and ongoing research efforts across the organization's diverse operational and R&D departments for the past fiscal year. Our strength lies in the cross-pollination of ideas and methodologies, driving innovation and addressing complex challenges that transcend traditional disciplinary boundaries. This year's review highlights significant progress in ten critical areas. Advances in **Medical Research** focused on the rare XDR-471 syndrome, yielding new diagnostic insights. Concurrently, **Software Engineering** tackled persistent stability issues, implementing key fixes identified through error code analysis (e.g., `ERR_MEM_ALLOC_FAIL_0x8007000E`). **Financial Analysis** revealed mixed quarterly performance, prompting strategic reviews, particularly concerning resource allocation impacting R&D pipelines.\n",
      "\n",
      "Crucial developments were also seen in **Scientific Experimentation**, where novel material properties were characterized, potentially impacting future product lines. Our **Legal Developments** team navigated complex precedents, particularly in intellectual property related to the _Synergy Dynamics_ case, ensuring compliance and mitigating risk. **Product Engineering** finalized specifications for the next-generation Model Zircon-5, incorporating feedback from multiple teams. Insights from **Historical Research** into the Galveston Accords provided unexpected context for current market dynamics. **Project Management** successfully navigated critical phases for Project Cerberus despite resource constraints, documented through detailed progress reports. **Pharmaceutical Development** advanced Compound CTX-204b into further testing based on promising biomarker results. Finally, **Cybersecurity Analysis** addressed sophisticated threats, reinforcing our defenses based on detailed incident forensics. These collective efforts underscore the value of our integrated approach.\n",
      "\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      " Table of Contents\n",
      "\n",
      "1.  Executive Summary\n",
      "2.  Table of Contents\n",
      "3.  Methodology\n",
      "4.  Section 1: Medical Research - Understanding XDR-471 Syndrome\n",
      "5.  Section 2: Software Engineering - Project Phoenix Stability Enhancements\n",
      "6.  Section 3: Financial Analysis - Q3 Performance and Outlook\n",
      "7.  Section 4: Scientific Experimentation - Characterization of Material Composite XT-5\n",
      "8.  Section 5: Legal Developments - Navigating IP Precedents and Regulatory Shifts\n",
      "9.  Section 6: Product Engineering - Finalizing Model Zircon-5 Specifications\n",
      "10. Section 7: Historical Research - Re-evaluating the Galveston Accords (1921)\n",
      "11. Section 8: Project Management - Progress on Project Cerberus Phase 2B\n",
      "12. Section 9: Pharmaceutical Development - Compound CTX-204b Phase IIa Update\n",
      "13. Section 10: Cybersecurity Analysis - Incident Response Report\n",
      "14. Future Directions\n",
      "\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      " Methodology\n",
      "\n",
      "The insights compiled within this Annual Interdisciplinary Research Review represent a synthesis of findings drawn from standard departmental reporting cycles, specialized project updates, and cross-functional review meetings conducted throughout the year. Data sources included internal project databases, laboratory notebooks, financial reporting systems, legal case summaries, security incident logs, and minutes from dedicated working groups. A central review committee, comprising representatives nominated by each division head, was tasked with identifying key developments and potential cross-domain implications. This committee utilized a standardized reporting template to capture essential details, including unique identifiers (project codes, error numbers, case references, etc.) and progress metrics. Subsequent analysis focused on identifying thematic overlaps, shared challenges, and opportunities for synergistic development, forming the basis of this consolidated report. The ambiguous references employed reflect the internal context and assume reader familiarity with ongoing initiatives and personnel.\n",
      "\n",
      "\n",
      " -------------------------------- \n",
      " \n",
      " Section 1: Medical Research - Understanding XDR-471 Syndrome\n",
      "\n",
      "This year saw significant strides in our understanding of XDR-471 syndrome, a rare neurodegenerative condition previously hampered by diagnostic ambiguity. The team focused on correlating clinical presentations with specific genetic markers, particularly variations within the Gene LOC73b region. Analysis of patient cohort data (Cohort ID: XDR-EU-03) revealed a statistically significant link between symptom severity and marker expression levels, measured via quantitative PCR assays. Preliminary work on a novel diagnostic biomarker panel (Panel ID: XDR-BioMk-v2) shows promise, achieving >85% sensitivity in early validation sets. However, specificity remains a challenge requiring further refinement. Ongoing efforts under Trial ID: XDR-TR002 are exploring targeted therapeutic interventions based on these findings. These results provide a much-needed foundation for future clinical strategies, though the resource implications highlighted in Section 3 (Financial Analysis) may impact the pace of subsequent trial phases. The team continues to refine diagnostic protocols based on this evolving understanding.\n",
      "\n",
      "\n",
      " -------------------------------- \n",
      " \n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_by_section(text)\n",
    "\n",
    "for chunk in chunks[0:5]:\n",
    "    print(chunk + \"\\n\\n -------------------------------- \\n \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ce690",
   "metadata": {},
   "source": [
    "## 2. Text Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83ac72",
   "metadata": {},
   "source": [
    "Search problem: look through chunks and identify the most related to the user's question.\n",
    "\n",
    "1. **Semantic Search**: uses ***text embeddings*** to understand the meaning and context of question and chunks.\n",
    "    - We must choose an embedding model. Anthropic recommends **VoyageAI** for Claude models.\n",
    "2. **Keyword-based** *(not in this notebook)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01b8e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple embedding function\n",
    "def generate_embedding(chunks: str | list,\n",
    "                       model: str = \"voyage-3-large\",\n",
    "                       input_type: str = \"query\"\n",
    "):\n",
    "    is_list = isinstance(chunks, list)\n",
    "    input = chunks if is_list else [chunks]\n",
    "    result = embedding_client.embed(input, model, input_type)\n",
    "    return result.embeddings if is_list else result.embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_by_char(text)\n",
    "results = generate_embedding(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e79b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embedding: 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.07848451286554337,\n",
       " 0.030050374567508698,\n",
       " -0.007380018476396799,\n",
       " 0.006761334370821714,\n",
       " -0.003800488542765379,\n",
       " 0.03606044873595238,\n",
       " -0.03765135258436203,\n",
       " 0.02633826993405819,\n",
       " 0.00614265026524663,\n",
       " -0.010561822913587093,\n",
       " 0.006275225430727005,\n",
       " 0.0311109758913517,\n",
       " -0.0012318444205448031,\n",
       " -0.01228530053049326,\n",
       " -0.0233332309871912]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Length of embedding:\", len(results))\n",
    "results[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e9502",
   "metadata": {},
   "source": [
    "## 3. Search Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f8612",
   "metadata": {},
   "source": [
    "### 3.1 Embeddings, VectorDB and Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a4237",
   "metadata": {},
   "source": [
    "#### 3.1.1 Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5905b",
   "metadata": {},
   "source": [
    "User's query and chunk's embeddings are compared through Cosine Similarity to choose the most related chunk of text (cosine of the angle between 2 vectors – $\\theta$):\n",
    "\n",
    "**Cosine Similarity**\n",
    "$$\n",
    "Sim(A,B) = cos(\\theta) = \\frac{A \\cdot B}{||A||\\cdot||B||}\n",
    "$$\n",
    "* **1**: Exactly same direction\n",
    "* **0**: Perpendicular (independent)\n",
    "* **-1**: Completely opposite direction\n",
    "\n",
    "**Cosine Distance**\n",
    "$$1 - Similarity$$\n",
    "* **0**: Exactly same direction\n",
    "* **1**: Perpendicular (independent)\n",
    "* **2**: Completely opposite direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5384b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9825129171527335"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cosine Similarity\n",
    "def cosine_similarity(a: list[float], b: list[float]):\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError(\"Both entries must have the same length.\")\n",
    "    else:\n",
    "        dot_product = 0\n",
    "        magn_a = 0\n",
    "        magn_b = 0\n",
    "        for idx in range(len(a)):\n",
    "            dot_product += a[idx]*b[idx]\n",
    "            magn_a += a[idx]**2\n",
    "            magn_b += b[idx]**2\n",
    "        if magn_a == 0 or magn_b == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            cos_sim = dot_product/(sqrt(magn_a)*sqrt(magn_b))\n",
    "            return cos_sim\n",
    "        \n",
    "# Example usage\n",
    "a = [0.112, 0.993]\n",
    "b = [0.295, 0.955]\n",
    "\n",
    "cosine_similarity(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "178623ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9825129171527336"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np \n",
    "float(cosine_similarity(np.array([a]), np.array([b]))[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ab62d",
   "metadata": {},
   "source": [
    "#### 3.1.2 Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a39f51c",
   "metadata": {},
   "source": [
    "Match user's query and content by Cosine Distance.\n",
    "\n",
    "Five steps to follow:\n",
    "\n",
    "1. Chunk the text by section\n",
    "2. Generate embeddings for each chunk\n",
    "3. Create a vector store and add each embedding to it\n",
    "4. Generate an embedding for the user's question\n",
    "5. Search the store to find the most relevant chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "863fcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1,2. Chunk and generate embeddings\n",
    "chunks = chunk_by_section(text)\n",
    "embeddings = generate_embedding(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afc5e2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks) == len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be50a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate Vector store\n",
    "vec_store = VectorIndex()\n",
    "for embedding, chunk in zip(embeddings, chunks):\n",
    "    vec_store.add_vector(embedding, {\"content\": chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e51e5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Generate embedding for user's question\n",
    "user_query = \"What did the software engineering dept do last year?\"\n",
    "user_embedding = generate_embedding(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "037501f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Search vector store for match\n",
    "results = vec_store.search(user_embedding, 3) # get 3 top matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b75a1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Cosine Distance: 0.4820578028613297\n",
      "\n",
      "Content:\n",
      "  Section 2: Software Engineering - Project Phoenix Stability Enhancements\n",
      "\n",
      "The Software Engineering division dedicated considerable effort to improving the stability and performance of the core system\n",
      "\n",
      "------------------------------------------\n",
      "Cosine Distance: 0.48413100279652643\n",
      "\n",
      "Content:\n",
      "  Executive Summary\n",
      "\n",
      "This report synthesizes the key findings and ongoing research efforts across the organization's diverse operational and R&D departments for the past fiscal year. Our strength lies \n",
      "\n",
      "------------------------------------------\n",
      "Cosine Distance: 0.48764751365959746\n",
      "\n",
      "Content:\n",
      "  Future Directions\n",
      "\n",
      "This year's cross-domain insights underscore the interconnectedness of our diverse research and operational activities. The stability enhancements achieved in Software Engineering \n"
     ]
    }
   ],
   "source": [
    "# See best matches\n",
    "for result in results:\n",
    "    print(\"\\n------------------------------------------\")\n",
    "    print(\"Cosine Distance:\", result[1])\n",
    "    print(\"\\nContent:\\n\", result[0]['content'][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a508fea",
   "metadata": {},
   "source": [
    "### 3.2 Lexical Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af430c7e",
   "metadata": {},
   "source": [
    "When building RAG pipelines, you'll quickly discover that semantic search alone doesn't always return the best results. Sometimes you need exact term matches that semantic search might miss. The solution is to combine semantic search with lexical search.\n",
    "\n",
    "* **Semantic search** finds conceptually related content using embeddings.\n",
    "* **Lexical search** finds exact term matches using classic text search.\n",
    "* **Merged results** combine both approaches for better accuracy.\n",
    "\n",
    "#### BM25 (Best Match v. 25)\n",
    "\n",
    "1. Tokenize the query\n",
    "    Break the user's question into individual terms. For example, \"a INC-2023-Q4-011\" becomes [\"a\", \"INC-2023-Q4-011\"].\n",
    "\n",
    "2. Count term frequency\n",
    "    See how often each term appears across all your documents. Common words like \"a\" might appear 5 times, while specific terms like \"INC-2023-Q4-011\" might appear only once.\n",
    "\n",
    "3. Weight terms by importance\n",
    "    Terms that appear less frequently get higher importance scores. The word \"a\" gets low importance because it's common, while \"INC-2023-Q4-011\" gets high importance because it's rare.\n",
    "\n",
    "4. Find best matches\n",
    "    Return documents that contain more instances of the higher-weighted terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa4688e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a BM25 store and add documents\n",
    "bm25_store = BM25Index()\n",
    "for chunk in chunks:\n",
    "    bm25_store.add_document({\"content\": chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1812577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Search Results\n",
    "user_query = \"What happened with INC-2023-Q\"\n",
    "user_embedding = generate_embedding(user_query)\n",
    "vec_results = vec_store.search(user_embedding, 3) # get 3 top matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4b6eda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Cosine Distance: 0.52053258992134\n",
      "\n",
      "Content:\n",
      "  Section 2: Software Engineering - Project Phoenix Stability Enhancements\n",
      "\n",
      "The Software Engineering division dedicated considerable effort to improvin\n",
      "\n",
      "------------------------------------------\n",
      "Cosine Distance: 0.595024764747381\n",
      "\n",
      "Content:\n",
      "  Table of Contents\n",
      "\n",
      "1.  Executive Summary\n",
      "2.  Table of Contents\n",
      "3.  Methodology\n",
      "4.  Section 1: Medical Research - Understanding XDR-471 Syndrome\n",
      "5.  S\n",
      "\n",
      "------------------------------------------\n",
      "Cosine Distance: 0.6011882575100602\n",
      "\n",
      "Content:\n",
      "  Section 10: Cybersecurity Analysis - Incident Response Report: INC-2023-Q4-011\n",
      "\n",
      "The Cybersecurity Operations Center successfully contained and remedi\n"
     ]
    }
   ],
   "source": [
    "for content, score in vec_results:\n",
    "    print(\"\\n------------------------------------------\")\n",
    "    print(\"Cosine Distance:\", score)\n",
    "    print(\"\\nContent:\\n\", content['content'][:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "138893a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Distance: 0.522946695317638\n",
      "\n",
      "Content:\n",
      "  Section 2: Software Engineering - Project Phoenix Stability Enhancements\n",
      "\n",
      "The Software Engineering division dedicated considerable effort to improvin\n",
      "\n",
      "------------------------------------------\n",
      "Distance: 0.5591483528614661\n",
      "\n",
      "Content:\n",
      "  Section 10: Cybersecurity Analysis - Incident Response Report: INC-2023-Q4-011\n",
      "\n",
      "The Cybersecurity Operations Center successfully contained and remedi\n",
      "\n",
      "------------------------------------------\n",
      "Distance: 0.9391180106840461\n",
      "\n",
      "Content:\n",
      "  Methodology\n",
      "\n",
      "The insights compiled within this Annual Interdisciplinary Research Review represent a synthesis of findings drawn from standard departm\n"
     ]
    }
   ],
   "source": [
    "# 3. BM25 Store\n",
    "bm25_results = bm25_store.search(user_query, 3)\n",
    "\n",
    "# Printbm25_ results\n",
    "for doc, distance in bm25_results:\n",
    "    print(\"\\n------------------------------------------\")\n",
    "    print(\"Distance:\", distance)\n",
    "    print(\"\\nContent:\\n\", doc['content'][:150])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00123676",
   "metadata": {},
   "source": [
    "### 3.3 Hybrid Search - Multi-Index Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6137be8b",
   "metadata": {},
   "source": [
    "Create a <code>Retreiver</code> class that merges both indexes. \n",
    "\n",
    "#### Reciprocal Rank Fusion\n",
    "1. Rank by each index output\n",
    "2. Compute RRF score\n",
    "\n",
    "$$\n",
    "RRF\\_score(d) = \\sum_{i = 1}^{n} \\frac{1}{k + rank_i (d)}\n",
    "$$\n",
    "\n",
    "where $k$ is a constant, usually 60.\n",
    "\n",
    "3. Rank the RRF score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195047ea",
   "metadata": {},
   "source": [
    "**For example:**\n",
    "| Section | VectorIndex ranking | BM25 ranking | RRF Score (k = 1) | RRF ranking |\n",
    "|--|--|--|--|--|\n",
    "| 2. Software Engineering | 1 | 1 | $\\frac{1}{1+1} + \\frac{1}{1+1} = 1$ | 1 |\n",
    "| Table of Contents | 2 | - | $\\frac{1}{1+2} + \\frac{1}{1+4} = 0.533$ | 3 |\n",
    "| 10. Cybersecurity Analysis | 3 | 2 | $\\frac{1}{1+3} + \\frac{1}{1+2} = 0.583$ | 2 |\n",
    "| Methodology | - | 3 | $\\frac{1}{1+4} + \\frac{1}{1+3} = 0.45$ | 4 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16350c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorIndex(embedding_fn=generate_embedding)\n",
    "bm25_index = BM25Index()\n",
    "retriever = Retriever(vector_index, bm25_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7faf83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all chunks to the retriever, which internally passes them along to both indexes\n",
    "# Note: converted to a bulk operation to avoid rate limiting errors from VoyageAI (add_documents instead of add_document)\n",
    "retriever.add_documents([{\"content\": chunk} for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20c1caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What happened with INC-2023-Q\"\n",
    "results = retriever.search(user_query, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a33e04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "Score: 0.03278688524590164\n",
      "\n",
      "Content:\n",
      "  Section 2: Software Engineering - Project Phoenix Stability Enhancements\n",
      "\n",
      "The Software Engineering division dedicated considerable effort to improving the stability and performance of the core system\n",
      "\n",
      "------------------------------------------\n",
      "Score: 0.03200204813108039\n",
      "\n",
      "Content:\n",
      "  Section 10: Cybersecurity Analysis - Incident Response Report: INC-2023-Q4-011\n",
      "\n",
      "The Cybersecurity Operations Center successfully contained and remediated a targeted intrusion attempt tracked as `INC-\n",
      "\n",
      "------------------------------------------\n",
      "Score: 0.031024531024531024\n",
      "\n",
      "Content:\n",
      "  Methodology\n",
      "\n",
      "The insights compiled within this Annual Interdisciplinary Research Review represent a synthesis of findings drawn from standard departmental reporting cycles, specialized project update\n"
     ]
    }
   ],
   "source": [
    "# Print overall results\n",
    "for doc, score in results:\n",
    "    print(\"\\n------------------------------------------\")\n",
    "    print(\"Score:\", score)\n",
    "    print(\"\\nContent:\\n\", doc['content'][:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f20906a",
   "metadata": {},
   "source": [
    "## 4. LLM-Based Re-ranking\n",
    "\n",
    "Ask Claude to look at the user's question. We provide the chunks that seem to be relevant, and Claude will return the most relevant, re ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5e009d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude = ClaudeResponses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2111e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reranker_fn(docs, query_text, k):\n",
    "    joined_docs = \"\\n\".join(\n",
    "        [\n",
    "            f\"\"\"\n",
    "        <document>\n",
    "        <document_id>{doc[\"id\"]}</document_id>\n",
    "        <document_content>{doc[\"content\"]}</document_content>\n",
    "        </document>\n",
    "        \"\"\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are about to be given a set of documents, along with an id of each.\n",
    "    Your task is to select and sort the {k} most relevant documents to answer the user's question.\n",
    "\n",
    "    Here is the user's question:\n",
    "    <question>\n",
    "    {query_text}\n",
    "    </question>\n",
    "    \n",
    "    Here are the documents to select from:\n",
    "    <documents>\n",
    "    {joined_docs}\n",
    "    </documents>\n",
    "\n",
    "    Respond in the following format:\n",
    "    ```json\n",
    "    {{\n",
    "        \"document_ids\": str[] # List document ids, {k} elements long, sorted in order of decreasing relevance to the user's query. The most relevant documents should be listed first.\n",
    "    }}\n",
    "    ```\n",
    "\n",
    "    Do not include any reasoning. Return ONLY the json.\n",
    "    \"\"\"\n",
    "    claude.add_user_message(prompt)\n",
    "    claude.add_assistant_message(\"```json\")\n",
    "    result = claude.chat(return_text= True, stop_sequences = [\"´´´\"])\n",
    "\n",
    "    return json.loads(str(result))['document_ids']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e4c7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector index, a bm25 index, then use them to create a Retriever\n",
    "vector_index = VectorIndex(embedding_fn=generate_embedding)\n",
    "bm25_index = BM25Index()\n",
    "\n",
    "retriever = Retriever(bm25_index, vector_index, reranker_fn=reranker_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de50705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all chunks to the retriever, which internally passes them along to both indexes\n",
    "# Note: converted to a bulk operation to avoid rate limiting errors from VoyageAI\n",
    "retriever.add_documents([{\"content\": chunk} for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e2e7fc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "    \"document_ids\": [\"Z7wr\", \"faNd\"]\n",
      "}\n",
      "```\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 5 column 1 (char 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat did the eng team do with INC-2023-Q4-011?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(score, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, doc[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m:\u001b[32m200\u001b[39m], \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Cursos/Anthropic/ClaudeAPI/lib/SearchStrategiesClass.py:473\u001b[39m, in \u001b[36mRetriever.search\u001b[39m\u001b[34m(self, query_text, k, k_rrf)\u001b[39m\n\u001b[32m    467\u001b[39m         doc[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    468\u001b[39m             random.choices(\n\u001b[32m    469\u001b[39m                 string.ascii_letters + string.digits, k=\u001b[32m4\u001b[39m\n\u001b[32m    470\u001b[39m             )\n\u001b[32m    471\u001b[39m         )\n\u001b[32m    472\u001b[39m doc_lookup = {doc[\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m]: doc \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs_only}\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m reranked_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reranker_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m new_result = []\n\u001b[32m    476\u001b[39m original_scores = {\u001b[38;5;28mid\u001b[39m(doc): score \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m result}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mreranker_fn\u001b[39m\u001b[34m(docs, query_text, k)\u001b[39m\n\u001b[32m     38\u001b[39m claude.add_assistant_message(\u001b[33m\"\u001b[39m\u001b[33m```json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m result = claude.chat(return_text= \u001b[38;5;28;01mTrue\u001b[39;00m, stop_sequences = [\u001b[33m\"\u001b[39m\u001b[33m´´´\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mdocument_ids\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.12_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.12_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/decoder.py:340\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 5 column 1 (char 42)"
     ]
    }
   ],
   "source": [
    "results = retriever.search(\"what did the eng team do with INC-2023-Q4-011?\", 2)\n",
    "\n",
    "for doc, score in results:\n",
    "    print(score, \"\\n\", doc[\"content\"][0:200], \"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2cf42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
